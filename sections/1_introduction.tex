%!TEX root = ../thesis.tex
\chapter{Introduction}
In data mining and statistics deriving knowledge from observational data is used to find correlations between variables in the data. Through those correlations, data distribution characteristics are found. Correlation does not imply causation, which means that causality information must be gathered to understand the data and found correlation thoroughly. 

There are many fields where causal relationships of particular interest. Causal structure learning is, for example, used to derive gene regulatory networks. The inference of gene regulatory networks in medicine or, more specifically, genetic research can help to estimate causal effects among genes \cite{rauJointEstimationCausal2013}
Since many use cases of causal structure learning profit from faster results and datasets can be large-scale, leading to long execution times, a speedup in execution time is beneficial.
% motivation, Relevanz (Anwendungsfall, Daten etc warum Effizienz?)

Moore's Law \cite{mooreCrammingMoreComponents1965} says that transistors placed on an integrated circuit double approximately every two years. This law has been self-fulfilling, and this effect can be seen in the real world, indicating a steady processing performance gain. Still, modern processor development is getting to a physical limit, called the "Power Wall". More transistors that are more densely placed, with lower voltage and higher frequencies, produce more heat. While cooling performance has its physical limits, the "Power Wall" is hit at some point.

To work against this limit, modern processors incorporate multiple cores that work in parallel. Studies show that introducing additional cores on the same chip is also limited physically because of the growing density combined with heat and voltage limitations. This limitation is also called "dark silicon" because parts of the chip are disabled to counteract the overheating problem \cite{esmaeilzadehDarkSiliconEnd2011}.

Multi-core processors can speed up execution by splitting work and processing that work in parallel. However, parallelization has its limits and converges to an upper bound for any work and can be calculated by applying Amdahl's law\cite{amdahlValiditySingleProcessor1967}. Even for highly parallel algorithms that are designed for multi-core systems, the upper bound still exists.

One of the next logical steps for improving performance and optimizing execution speed despite the physical and algorithmic limitations is adding specialized processors to the system tailored for the given use case. Heterogeneous systems emerged. The processor best fitting for the work to be done is used to achieve optimal performance. Nevertheless, while one processor handles the work, the remaining processors may not be used, and additional computing power is wasted.

Heterogeneous computing tries to minimize the wasted computational power in heterogeneous systems by using as many resources as possible. Algorithms and applications are inspected, split into parts given their properties, such as computation or data dependency, and those parts are then placed onto the different processors. The execution time is reduced by using multiple specialized processors for the best fitting part of the executed work.

A downside of using multiple specialized processors is that the relative execution time of work done on heterogeneous processors is more complicated to estimate than on homogeneous processors. The estimation of execution time is an essential parameter for scheduling different parts of the work on each processor. On homogeneous systems, work is placed on any processor because deciding the execution unit does not influence the execution time. In contrast to that, heterogeneous systems use a scheduling algorithm that estimates resource utilization and handles placing the work on each processor. Such a scheduling algorithm is also called a load-balancer. Load-balancing is one of the primary focuses of this thesis algorithm design.

Another downside of heterogeneous systems is the importance of minimizing communication between the parts executed on different processors. The communication time spent is directly related to the interconnection speed between those processors. Modern heterogeneous system interconnects between processors are getting faster. Still, the interconnect between processors is one of the slowest connections in a computer. Therefore most heterogeneous computing solutions are limited by their interconnect bottleneck. This bottleneck is an essential part of heterogeneous computing that many solutions for heterogeneous systems are even slower while using all of the resources because of the communication overhead. Due to the importance of efficient communication designing heterogeneous algorithms essentially means solving the communication problem.

In this thesis, both the PC algorithm and heterogeneous computing are combined to an efficient PC algorithm variant that can be executed on a heterogeneous system to use its resources and get an additional speedup compared to the non-heterogeneous variant. The introduced variant of the PC algorithm incorporates load-balancing solutions to handle optimal resource utilization and optimizations regarding possible communication overhead. Experiments are done using the heterogeneously executed PC algorithm to analyze bottlenecks and the efficiency of the solution.

This thesis is structured starting with the theoretical background, followed by the problem statement. A solution for the problem statement is proposed, and this solution is evaluated. In the following, a more in-depth outline of this structure is given.

Basic terminology is introduced with the theoretical background chapter. While parallel programming is essential for parallelizing algorithms on heterogeneous systems, this topic is covered first. The basics of heterogeneous computing and constraint-based causal structure learning are elaborated in the second part of the background chapter.

After that, in the problem statement chapter, the research question is developed using the acquired terminology and explaining the problem state which is aimed to be solved. In this chapter, the basis for the proposed heterogeneous parallelization of the PC algorithm is laid. Following the problem statement, the heterogeneous PC algorithm is developed in the heterogeneous causal structure learning chapter using Fosters' Methodology. Fosters' Methodology is one of the standard methods to parallelize algorithms, even in heterogeneous system contexts. Distributing multiple parts of the work to be executed on multiple processors is called scheduling; doing that with resource utilization in mind is also called load-balancing. By inspecting an optimized load-balancing for the parallelized PC algorithm, two approaches are worked out and explained.

In the experiments chapter, those two approaches are tested using benchmarks with different parameters on multiple systems. Then the work on the heterogeneous PC algorithm is connected to related work. A discussion on the viability of both approaches based on the experimental results is started in the discussion chapter. The problem statement is linked to the experiments' results, and the research question is answered.

At the end of the thesis, future work is elaborated that could help solidify the results or produce even better results.

% Trend hardware? heterogene (vllt dark silicon)
% moores law
% processing speed i limited an does not grow any longer (physics, get too hot when more dense) => dynamic power, power wall
% ILP wall? maybe too detailed
% memory wall (memory speed, and latency limited)
% Dark silicon = next step / power wall 2.0
% - multi-core scaling limited as well
% 
% - specialized hardware has potential
% - speedup through using the right processor for the correct task
% - Needs alot more software optimizations
% speedup for what?
% - medical causations => The faster, the better
% - when doing multiple experiments/iterations on data, small speedup can mean alot
% - energy efficiency, by optimal resource usage
% - some processing units are more efficient

% Outline, structure

% Teaser auf problem statement

% Womit muss man sich auseinandersetzen (load balanacing)