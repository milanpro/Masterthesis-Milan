%!TEX root = ../thesis.tex
\chapter{Problem Statement}
\label{chap:problem_statement}
Efforts for a more efficient PC algorithm execution have been made for versions running solely on the CPU or GPU. Since the skeleton discovery phase can be highly parallelizable, GPU variants mostly outperformed variants running on the CPU. In both variants, the other processing unit idles, and its processing power is unused. A solution to the wasted processing power could be using both processing units simultaneously and splitting the workload accordingly.
Splitting the workload into predefined, equal-sized tasks can help in the parallelization process. For scheduling such split tasks on homogeneous processing units, a simple load-balancing approach, such as splitting all tasks into equal-sized task-batches and placing them on the available processors, is sufficient.
Because of their equal processing power, the homogeneous processors should process these task-batches in the same time frame.
Workload balancing is more complex in heterogeneous systems than in homogeneous systems because of the additional parameters influencing the execution. These additional parameters can be the existence of complex interconnects for communication between the processors or parameters emerging from the heterogeneity of the processors. For example, a modern CPU has few but fast processing cores, being good at processing a few tasks with high load. In contrast, modern GPUs have multiple slower processing cores that process many tasks in parallel.

The aforementioned challenges, in combination with the development of a heterogeneous PC algorithm, can be summarized with the following research question:

\textit{How can the resources of a heterogeneous system be optimally used to accelerate the execution of the PC algorithm?}

The research question splits into a few smaller questions that are important to answer the research question itself and allow a finer-grained view of the problem:

\begin{enumerate}
  \item What tasks to define in the workload of the PC algorithm?
  \item How to parallelize the workload in a heterogeneous context?
  \item How to schedule the workload efficiently on those processing units?
  \item What performance parameters are important on heterogeneous systems?
\end{enumerate}

An adequately chosen task size is critical for being able to schedule the workload efficiently. Using a size-fixed task to parallelize a given workload is then effectively assigning the tasks to the processing units. A scheduling algorithm assigns tasks to the processing units. The scheduling algorithm takes the performance parameters of the heterogeneous system and its processing units into consideration.
Performance parameters such as the processing capabilities of the different processing units are essential factors for scheduling decisions. The single-core performance of the CPU is derived from the clock speed and the implemented instruction-level parallelism. Both performance indicators stalled in their development a few years ago \cite{sutterFreeLunchFundamental2005}. Most performance advancements are done by adding parallelism concepts such as multiple cores and SIMD instruction set extensions. Therefore, highly parallelizable workloads gain the most performance when run on CPUs with multiple cores and SIMD extensions. The same applies to GPUs, which are designed for executing parallelizable workloads.
The similarity between GPU and modern CPU parallelization allows for a similar algorithm implementation for both processing unit types.

Another critical performance parameter is the type of interconnect between the processing units. While accessing data available in the local processing unit memory is fast,  data access elsewhere has to use an interconnect and thus is relatively slow. Data movement between CPU and GPU in heterogeneous systems is widely known as the main bottleneck. A solution to reduce the relevance of that bottleneck is limiting communication between both \cite{hazarikaSurveyMemoryManagement2019}.

Some workloads are prone to being more communication reliant because of their data access patterns. The PC algorithm is one of those communication-reliant workloads since the separation sets can contain any vertex of the vertice set per independence test, and due to that, the access pattern can be compared to random memory access. Random memory access prevents standard optimizations such as prefetching and caching to avoid direct memory access. Mapping independence tests with overlapping separation sets to one processing unit is limited in its effectiveness due to the possibility of connections between any vertex. Speeding up such a workload on heterogeneous systems is possible through faster interconnects between the processing units. The interconnect speed still doubles every few years \cite{NVLink2021}, and newer interconnect standards can significantly impact heterogeneous computing performance.
Hardware limitations, such as interconnect speed and performance improvements, lead to another research question this thesis aims to answer:

\textit{Are modern CPU-GPU interconnects such as PCIe or NVLink able to overcome the bottleneck of random memory access workloads such as the PC-stable Algorithm?}

In the experiment section, benchmarks of both PCIe and NVLink based systems are done and later evaluated for insights on the performance impacts.
% Scaling?
% Contributions, Challenges?