%!TEX root = ../thesis.tex
\chapter{Problem Statement}
Efforts for a more efficient PC Algorithm have been made for versions running solely on the CPU or GPU. Since the skeleton discovery phase can be highly parallelizable, GPU variants mostly outperformed variants running on the CPU. In both variants, the other processor idles, and its processing power is unused. A solution to this problem could be using both processing units simultaneously and split the workload accordingly.
Splitting the workload into predefined tasks can help to parallelize the workload. For scheduling such split tasks on homogeneous processing units, a simple load balancing such as splitting the task load into equal size batches and placing them on the available processors is sufficient.
Because of their equal processing power, those homogeneous processors should process these task batches in the same time frame.
Heterogeneous systems are more complex than homogeneous for balancing the workload because of the additional parameters influencing the execution. For example, a modern CPU has few but fast processing cores, being good at processing a few tasks with high load. In contrast, the modern GPU has multiple slower processing cores that process many parallel tasks concurrently.

On this basis, the following research questions arise: How to optimally use the resources of a heterogeneous system to speed up the PC Algorithm execution?
The research question splits into a few smaller questions that are important to answer the research question itself and allow a finer-grained view of the problem:

\begin{enumerate}
  \item What tasks to define in the workload of the PC-Algorithm?
  \item How to parallelize the workload in a heterogeneous context?
  \item How to schedule the workload effectively on those processing units?
  \item What performance parameters are important on heterogeneous systems?
\end{enumerate}

Deciding on a task size is the main factor in being able to schedule the workload effectively. Using this task to parallelize the workload is then effectively assigning the tasks to the given processing units. Assigning the task to the given processing units has to be done by some scheduling algorithm, which has to know about the performance parameters of the heterogeneous system and its processing units.
Performance parameters such as the processing power of the different processing units are important factors for that decision. The single core performance of the CPU is derived from the clock speed and the implemented instruction level parallelism. Both performance indicators stalled in their development a few years ago \cite{sutterFreeLunchFundamental2013}. Most performance advancements are done by adding parallelism concepts such as multiple cores and SIMD instruction set extensions. Therefore highly parallelizable workloads gain the most performance when run on modern CPUs. The same applies to GPUs which are dedicated to execute parallelizable workloads.
This allows for a similar algorithm implementation used for the different processing units.

A more important performance parameter is the interconnect between the processing units. While accessing data that is available in the local processing unit memory is fast, accessing data elsewhere has to go over an interconnect. Data movement between CPU and GPU in heterogeneous systems is widely known as the main bottleneck where the best solution is limiting communication between both \cite{hazarikaSurveyMemoryManagement2019}. Some workloads are prone to being more communication reliant, because of their data access patterns. The PC-Algorithm is one of those communication reliant workloads, since the seperation sets can contain any vertex of the vertex set per independence test and due to that the access pattern can be compared to a random memory access. Mapping independence tests with overlapping seperation sets to one processing unit is not trivial and limited in its effectiveness due to the possibility of connections between any vertex. Speeding up such a workload on heterogeneous systems is possible through faster interconnects between the processing units. The interconnect speed still doubles regularly over time \cite{NVLink2021} and newer interconnect standards can severely impact heterogeneous computing performance.
Those hardware limitations and performance improvements lead to another reasearch question this thesis aims to answer:

Are modern CPU-GPU interconnects such as PCIe or NVLink able to overcome the bottleneck of random memory access workloads such as the PC-stable Algorithm?

In the experiment section benchmarks of both PCIe and NVLink based systems are done and later evaluated for insights in the performance inpacts of those interconnects.