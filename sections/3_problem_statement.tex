%!TEX root = ../thesis.tex
\chapter{Problem Statement}
\label{chap:problem_statement}
Efforts for a more efficient PC algorithm execution have been made for versions running solely on the CPU or GPU. Since the skeleton discovery phase can be highly parallelizable, GPU variants mostly outperformed variants running on the CPU. In both variants, the other processor idles, and its processing power is unused. A solution to the wasted processing power could be using both processing units simultaneously and splitting the workload accordingly.
Splitting the workload into predefined, equal-sized tasks can help to parallelize the workload. For scheduling such split tasks on homogeneous processing units, a simple load-balancing such as splitting all tasks into equal-sized task-batches and placing them on the available processors is sufficient.
Because of their equal processing power, those homogeneous processors should process these task-batches in the same time frame.
Heterogeneous systems are more complex than homogeneous for balancing the workload because of the additional parameters influencing the execution. Those additional parameters can be complex interconnects for communication between the processors or parameters emerging from the heterogeneity of the processors. For example, a modern CPU has few but fast processing cores, being good at processing a few tasks with high load. In contrast, the modern GPU has multiple slower processing cores that process many parallel tasks concurrently.

On this basis, the following research question arises: How to optimally use the resources of a heterogeneous system to speed up the PC algorithm execution?
The research question splits into a few smaller questions that are important to answer the research question itself and allow a finer-grained view of the problem:

\begin{enumerate}
  \item What tasks to define in the workload of the PC algorithm?
  \item How to parallelize the workload in a heterogeneous context?
  \item How to schedule the workload effectively on those processing units?
  \item What performance parameters are important on heterogeneous systems?
\end{enumerate}

Deciding on a task size is the main factor in being able to schedule the workload effectively. Using this task to parallelize the workload is then effectively assigning the tasks to the given processing units. Assigning the task to the given processing units has to be done by some scheduling algorithm, which has to know about the performance parameters of the heterogeneous system and its processing units.
Performance parameters such as the processing power of the different processing units are essential factors for that decision. The single-core performance of the CPU is derived from the clock speed and the implemented instruction-level parallelism. Both performance indicators stalled in their development a few years ago \cite{sutterFreeLunchFundamental2005}. Most performance advancements are done by adding parallelism concepts such as multiple cores and SIMD instruction set extensions. Therefore highly parallelizable workloads gain the most performance when run on modern CPUs. The same applies to GPUs, which are dedicated to executing parallelizable workloads.
The similarity between GPU and modern CPU parallelization allows for a similar algorithm implementation used for the different processing units.

Another critical performance parameter is the interconnect between the processing units. While accessing data available in the local processing unit memory is fast, accessing data elsewhere has to go over an interconnect and thus is relatively slow. Data movement between CPU and GPU in heterogeneous systems is widely known as the main bottleneck where the best solution is limiting communication between both \cite{hazarikaSurveyMemoryManagement2019}. Some workloads are prone to being more communication reliant because of their data access patterns.

The PC algorithm is one of those communication-reliant workloads since the separation sets can contain any vertex of the vertice set per independence test, and due to that, the access pattern can be compared to random memory access. Mapping independence tests with overlapping separation sets to one processing unit is not trivial and is limited in its effectiveness due to the possibility of connections between any vertex. Speeding up such a workload on heterogeneous systems is possible through faster interconnects between the processing units. The interconnect speed still doubles regularly over time \cite{NVLink2021} and newer interconnect standards can severely impact heterogeneous computing performance.
Those hardware limitations and performance improvements lead to another research question this thesis aims to answer:

Are modern CPU-GPU interconnects such as PCIe or NVLink able to overcome the bottleneck of random memory access workloads such as the PC-stable Algorithm?

In the experiment section, benchmarks of both PCIe and NVLink based systems are done and later evaluated for insights on the performance impacts of those interconnects.
% Scaling?
% Contributions, Challenges?