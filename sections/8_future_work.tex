%!TEX root = ../thesis.tex
\chapter{Future Work}
This thesis experiments rely on the same dataset with different sized variable samples. Although this helps getting a first good impression on the effectiveness of the approaches, there is still a bias in the experiment result regarding the datasets structure and edge deletion behavior. If the edge deletion state of the graph is different, there is expected to be a different effectiveness outcome. While a greater difference in outlier versus non outlier task length could result in more effective outlier scheduling on the CPU, less to no outlier occurence should make the GPU-only variant more effective.

This dataset behavior could be tested by executing the benchmarks with a different alpha value, which directly influences the amount with which edges are deleted. Another way of testing is generating datasets, that definetely shows one of the said behvaiors.

For better comparison, other real-world dataset experiments could be done. There are multiple gene  expression datasets, that are often used in the context of benchmarking the PC algorithm, such as NCI-60, MCC or BR51 \cite{leFastPCAlgorithm2019}. By executing benchmarks with said datasets, direct comparisons to state-of-the-art methods could be done, to get a better understaning of the performance implications of both approaches.

The approaches shown in this thesis are not dependent on some specific CI-test. For simplicity every benchmark was done using a CI-test that fits the discrete normal distribution. For other distributions such as continous or categorical data, other tests are used \cite{scutariLearningBayesianNetworks2010}. Those other tests are in need of other data structures and can change the data access patterns significantly. With other data access patterns, the data dependencies between tasks change and therefore the interconnect between CPU and GPU has to be used in other ways. Testing other CI-test could help getting insights on how those tests fit the heterogeneous computing setting.

The two used heterogeneous systems called Delos and AC922 the experiments are based on showed, that the underlying system/hardware specifications are important for the execution of heterogeneous computing. To get a deeper understanding of the influences, additional systems could be added to the experiments. Those systems could feature different performance disparities between CPU and GPU, to get further insights into the effects of the hardware in contrast to the interconnect. Adding multiple GPU benchmarks, could also be interesting to test and profile execution times on. Sometimes two different system GPUs are directly connected to two different system CPUs. In such system a more intelligent scheduling algorithm could be benefitial, that identifies, which task to steal from which GPU for best performance.

Heterogeneous systems do not only consist of CPUs and GPUs. There are many different kinds of processing units, that could also support the algorithms execution. One of the also widely know processing unit is called Field Programmable Gate Array (FPGA). FPGAs can be programmed to mimic a computer-chip specifically designed for a purpose. The developer is in charge to decide what gate is connected to which and designs hardware via software. An FPGA is more efficient in comparison to CPU and GPU, when used correctly, \cite{qasaimehComparingEnergyEfficiency2019} and could be added to the heterogeneous computing solution proposed in this thesis to accelerate further.
% Test with different dataset charateristics
% Test with Stronger CPU/GPU disparity
% Add FPGA
% 