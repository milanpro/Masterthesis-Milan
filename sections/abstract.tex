%!TEX root = ../thesis.tex
\chapter*{Abstract}
Constraint-based causal structure learning algorithms are used to derive causal relationships between variables in observational data. State-of-the-art methods are limited mainly by their long execution time, especially for large and high-dimensional datasets. The performance of constraint-based causal structure learning algorithms such as the PC algorithm is essential for time-dependent and energy-efficient computing. Modern high-performance computing systems mainly consist of conventional processors assisted by specialized processing units such as the graphics processing unit (GPU). Algorithms developed with heterogeneous systems in mind use the system resources and enable full processor utilization. The PC algorithm, which is not designed for heterogeneous systems, has to be adapted to heterogeneous computing. In this thesis, the PC algorithm is parallelized using two different approaches to utilize heterogeneous CPU-GPU systems. The PC algorithm is defined independently from the underlying dataset distribution. Yet, in this thesis datasets are assumed to be multivariate normal distributed. The first approach is a static scheduling approach that balances the work pre-execution, and the second approach is based on workstealing algorithms balancing the split work during execution dynamically. An experimental evaluation of both approaches shows that speedup is achievable even if communication and balancing overhead can limit the parallelization effect. Evaluating the approaches in comparison to the GPU-only accelerated PC algorithm shows that dynamic scheduling on both the CPU and GPU through the workstealing-based approach outperforms the GPU-only solution by 16,5\%. In situations where memory limits are reached on the GPU, speedup factors of up to 6,61 are possible.
% Outline the whole thesis
% motivation etc
% what steps are done
% which results where found

\chapter*{Zusammenfassung}
% abstract übersetzen
Constraint-basierte kausale Strukturlernalgorithmen werden verwendet, um kausale Beziehungen zwischen Variablen in Beobachtungsdaten abzuleiten. Methoden nach dem Stand der Technik sind vor allem durch ihre lange Ausführungszeit begrenzt, insbesondere bei großen und hochdimensionalen Datensätzen. Die Leistungsfähigkeit von constraint-basierten kausalen Strukturlernalgorithmen wie dem PC Algorithmus ist essentiell für zeitabhängiges und energieeffizientes Rechnen. Moderne High-Performance-Computing-Systeme bestehen hauptsächlich aus konventionellen Prozessoren, die von spezialisierten Recheneinheiten wie der Graphics Processing Unit (GPU) unterstützt werden. Algorithmen, die mit Blick auf heterogene Systeme entwickelt wurden, nutzen die Systemressourcen und ermöglichen eine volle Prozessorauslastung. Der PC Algorithmus, der nicht für heterogene Systeme konzipiert ist, muss an das heterogene Computing angepasst werden. In dieser Arbeit wird der PC Algorithmus mit zwei verschiedenen Ansätzen parallelisiert, um heterogene CPU-GPU Systeme zu nutzen. Der PC Algorithmus ist unabhängig von der zugrunde liegenden Datensatzverteilung definiert. In dieser Arbeit wird jedoch davon ausgegangen, dass die Datensätze multivariat normalverteilt sind. Der erste Ansatz ist ein statischer Scheduling-Ansatz, der die Arbeit vor der Ausführung verteilt, und der zweite Ansatz basiert auf Workstealing-Algorithmen, die die aufgeteilte Arbeit während der Ausführung dynamisch verteilen. Eine experimentelle Auswertung beider Ansätze zeigt, dass eine Beschleunigung erreichbar ist, auch wenn Kommunikations- und Balancierungs-Overhead den Parallelisierungseffekt begrenzen können. Die Evaluierung der Ansätze im Vergleich zum rein GPU-beschleunigten PC Algorithmus zeigt, dass das dynamische Scheduling sowohl auf der CPU als auch auf der GPU durch den Workstealing-basierten Ansatz die reine GPU-Lösung um 16,5\% übertrifft. In Situationen, in denen Speichergrenzen auf der GPU erreicht werden, sind Beschleunigungsfaktoren von bis zu 6,61 möglich.
