%!TEX root = ../thesis.tex
\chapter{Background}
In this chapter, we will look into heterogeneous computing, heterogeneous systems and the processing units frequently used in such systems. While heterogeneous systems power heterogeneous computing algorithms, they can consist of processing units of all kinds. This thesis focus lies on the \acrfull{CPU} and the \acrfull{GPU} as the processing power of a heterogeneous system.
After that the theoretical background of Causal Structure Learning and the PC-algorithm will be explained, which we will connect to the possible execution on heterogeneous systems.

\section{Heterogeneous Computing}
Heterogeneous computing refers to systems which include conventional as well as specialized processors. Those different processors work cooperatively on the same workload. \cite{heterogprocessing} Heterogeneous computing aims to use more than one processing unit of the systems resources and increase the execution effectiveness. Heterogeneity in the computing context refers to different instruction-set architectures (ISA), which means that the processors in this system are heterogeneous in their architecture.
Abstractions can eliminate this heterogeneity for the software developer, but since those processors have different advantages and disadvantages over another the developer still has to think on the optimal usage of such.

Most modern computing systems are heterogeneous and consist of one or more \acrshort{CPU} and one or more \acrshort{GPU}. Therefore a heterogeneous computing approach could be beneficial in their effectiveness for such systems. Both, the \acrshort{CPU} and the \acrshort{GPU} are very different in their architecture and function, so most modern applications only use one of those processors effectively.

\subsection{Central Processing Unit}
The \acrshort{CPU}, sometimes also just called processor, is the main instruction executing component of a computer. While modern \acrshort{CPU}s introduce parallelism concepts, the main purpose is still low latency execution of given instructions.
Without those later introduced parallelism concepts, a \acrshort{CPU} is only able to execute instructions in a serial manner. The ability to run concurrent applications is mostly done by introducing a thread and scheduling concept, which switches those threads periodically using a set of rules. Programs can create such threads using an operating system interface.
Modern \acrshort{CPU}s have multiple so called cores, which can independently execute instructions and therefore are able to run multiple threads in parallel. This is also called task-level parallelism.
Concurrent programs are prone to memory access errors in shared resources. Such errors need mechanisms such as critical sections for safe concurrent access. Such access mechanisms are also important in heterogeneous computing where concurrent memory access of multiple processors can occur.
Frameworks such as OpenMP can help the developer to handle multithreading and safe concurrency with abstractions of those concepts. OpenMP, a shared/memory parallel programming framework for C/C++ and Fortran framework, helps annotating parallel regions like parallelizable for loops and creates multiple execuion threads for those regions using a runtime.
The thesis project uses OpenMP for efficiency and parallelism purposes.
% OpenBlas armadillo boost SIMD AVX?

\subsection{Graphics Processing Unit}
The \acrshort{GPU} handles graphics processing in computer systems. In the beginning video games were the main driver for technical advancements in deveolping better \acrshort{GPU}s. For computing graphics the processing of mutliple things in parallel is essantially. The same operation has to be done on multiple voxels or vertices. Other use cases such as machine learning algorithms later also extensively used the systems \acrshort{GPU}, because of their parallelizability and frameworks such as OpenCL or CUDA, that made developing programs running on the GPU easier.
CUDA is a superset language of C/C++ that allows the definition of functions, that can be run on the \acrshort{GPU}. The Nvidia CUDA compiler compiles CUDA code which then runs on the GPU as well as CUDA code that uns on the host processor.
%% TODO


\subsection{Constraint Based Causal Structure Learning}
In this section, I introduce necessary terminology in the context of Causal Structure Learning which is the problem class I look into in this thesis. This section introduces the Causal Graphical Model and the PC-Algorithm based on the definition given by Schmidt et al \cite{constraintgpu}. The PC-Algorithm is the base for the heterogeneous approach this thesis is about.

\subsubsection{Causal Graphical Model}
Given a finite set of $N$ vertices $V = (V_1,...,V_N)$ and a set of edges $E \subseteq V \times V$, let $G = (V,E)$. The vertices each represent an observation. An edge $(V_i, V_j) \in E$ is called directed, i.e., $V_i \rightarrow V_j$, if $(V_i,V_j) \in E$ but $(V_j, V_i) \notin E$. An edge is called undirected, if both $(V_i,V_j) \in E$ and $(V_j, V_i) \in E$, i.e. $V_i - V_j$. Two vertices $V_i$, $V_j$ are called adjacent if there is an undirected edge $V_i - V_j$. The adjacenecy set $adj(G, V_i)$ of the vertex $V_i \in V$ in $G$ are all vertices $V_j \in V$ that are connected to $V_i$ by an undirected edge.

Some graph $G$ where all edges are directed and $G$ does not contain any cycle is a Directed Acyclic Graph (DAG). In the context of Causal Structure Learning a directed edge $E$ in such a DAG represents a direct causal relationship between the connected vertices.
The d-seperation criterion used in the DAG, enables information aboout the conditional independence between variables. Two variables $V_i, V_j \in V$ are conditionally independent given a set $S \subset V \backslash \{V_i, V_j\}$ if the vertices $V_i$ and $V_j$ are d-seperated by the set $S$, which is called seperation set.
A distribution $P$ of the variable set $V_1, ..., V_N$ that satisfies the above condition is called faithful.
Several different DAGs, that describe the same conditional independence information, form a Markov equivalent class. \cite{10.2307/2242556}. If two DAGs are Markov equivalent, they share the same skeleton $C$, i.e. the underlying undirected graph, and the same v-structures.
These v-structures are triples $V_i,V_j,V_k$ with $(V_i,V_k) \notin E$ and $(V_k,V_i) \notin E$ and directed edges $V_i \rightarrow V_j$ and $V_k \rightarrow V_j$. Moreover, it is possible to uniquely describe the corresponding Markov equivalent class by a Complete Partially Directed Acyclic Graph (CPDAG) \cite{10.1162/153244303321897717}.
A CPDAG is a partially directed acyclic graph where all DAGs in the Markov equivalence class incorporate the dame directed edges, and there exist two DAGs that incorporate the two directed versions of every undirected edge $V_i - V_j$ in the Markov equivalence class.
Hence, the focus lies on the estimation of the equivalence class of the DAG G based on the corresponding probability distribution $P$ of the involved variables $V_1,...,V_N$. In particular, under the assumption that the distribution $P$ is generated from the true causal DAG $G$, there is an edge $V_i - V_j$ in the skeleton of $G$ if and only if $V_i,V_j$ are dependent given all $S \subseteq V\backslash \{V_i,V_j\}$ \cite{causationpredic}.
Hence, the examination of the conditional independence information of the observed variables $V_1,...,V_N$ allows for the estimation of the undirected skeleton $C$ of the corresponding DAG $G$. The extension of the skeleton $C$ to the equivalence class of the DAG $G$ can be done by the repeated application of deterministic edge orientation rules on the skeleton \cite{JMLR:v15:colombo14a,10.5555/1248659.1248681,Pearl+2010}.